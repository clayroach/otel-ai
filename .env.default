# Environment Variables for AI-Native Observability Platform
# Copy this file to .env and fill in your API keys

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7
OPENAI_ENDPOINT=https://api.openai.com/v1

# Claude/Anthropic Configuration
CLAUDE_API_KEY=your_claude_api_key_here
CLAUDE_MODEL=claude-3-sonnet-20240229
CLAUDE_MAX_TOKENS=4096
CLAUDE_TEMPERATURE=0.7
CLAUDE_ENDPOINT=https://api.anthropic.com

# Local Model Configuration (LM Studio)
LM_STUDIO_ENDPOINT=http://localhost:1234/v1
LM_STUDIO_MODEL=openai/gpt-oss-20b

# LLM Manager Configuration
LLM_ROUTING_STRATEGY=preference
LLM_CACHE_ENABLED=true
LLM_CACHE_TTL_SECONDS=3600

# Model Preference Configuration (ordered by priority)
# General purpose models (for analysis, reasoning, general queries)
LLM_GENERAL_MODEL_1=claude-3-sonnet-20240229
LLM_GENERAL_MODEL_2=gpt-4-turbo-preview
LLM_GENERAL_MODEL_3=gpt-oss-120b

# SQL-specific models (for SQL generation, database queries)
LLM_SQL_MODEL_1=sqlcoder-7b-2
LLM_SQL_MODEL_2=codellama-7b-instruct
LLM_SQL_MODEL_3=deepseek-coder-v2-lite-instruct

# Local LLM Endpoint (for local models)
LLM_ENDPOINT=http://localhost:1234/v1

# Skip LLM tests in CI (set to true in CI environments)
SKIP_LLM_TESTS=false

# Database Configuration
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_DATABASE=otel_ai
CLICKHOUSE_USERNAME=default
CLICKHOUSE_PASSWORD=

# S3/MinIO Configuration
S3_ENDPOINT=http://localhost:9000
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_BUCKET=otel-traces
S3_REGION=us-east-1

# Development Configuration
NODE_ENV=development
LOG_LEVEL=info
PORT=3000