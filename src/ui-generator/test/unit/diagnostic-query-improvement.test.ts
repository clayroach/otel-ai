import { describe, it, expect } from "vitest"

/**
 * Test suite for analyzing and improving diagnostic query effectiveness
 * 
 * This test examines real-world generated queries and identifies ways to make them
 * more useful for actual issue diagnosis in critical paths.
 */

interface QueryAnalysis {
  originalQuery: string
  description: string
  diagnosticLimitations: string[]
  suggestedImprovements: string[]
  improvedQuery?: string
  expectedDiagnosticValue: string[]
}

describe("Diagnostic Query Improvement Analysis", () => {
  
  describe("Current Query Analysis", () => {
    
    it("should analyze the checkout flow latency query for diagnostic value", () => {
      // This is the actual query generated by the LLM for the checkout flow
      const currentCheckoutQuery = `
        SELECT 
            toDateTime(toStartOfHour(start_time)) AS hour,
            service_name,
            quantile(0.5)(duration_ns / 1e6)   AS p50_ms,
            quantile(0.95)(duration_ns / 1e6)  AS p95_ms,
            quantile(0.99)(duration_ns / 1e6)  AS p99_ms
        FROM otel.traces
        WHERE 
            service_name IN ('frontend', 'cart', 'checkout', 'payment', 'email')
            AND start_time >= toDateTime('2024-01-01 00:00:00')
        GROUP BY hour, service_name
        ORDER BY hour, service_name
      `
      
      const analysis: QueryAnalysis = {
        originalQuery: currentCheckoutQuery,
        description: "Checkout Flow Latency Analysis - Service-level percentile metrics by hour",
        diagnosticLimitations: [
          "No error analysis - doesn't show why path is 'critical'",
          "No cross-service correlation - can't identify bottleneck relationships", 
          "No comparison to SLA/baseline - can't determine if latencies are problematic",
          "No trace-level analysis - missing transaction flow insights",
          "No volume context - high latency could be due to low throughput",
          "No resource correlation - missing CPU/memory context for latencies",
          "Hour-level aggregation too coarse for real-time diagnosis",
          "Missing operation-level breakdown within services"
        ],
        suggestedImprovements: [
          "Add error rate analysis to identify failure points",
          "Include request volume to contextualize performance",
          "Add trace flow analysis to show service dependencies", 
          "Compare current metrics to historical baselines",
          "Include operation-level detail for service bottlenecks",
          "Add minute-level resolution for recent time windows",
          "Correlate with resource metrics when available",
          "Identify anomalies using statistical thresholds"
        ],
        expectedDiagnosticValue: [
          "Identify which service in the checkout flow is the bottleneck",
          "Understand if errors are causing performance degradation", 
          "See the relationship between request volume and latency",
          "Compare current performance to known-good baselines",
          "Pinpoint specific operations within services that are slow",
          "Detect recent performance regressions or spikes"
        ]
      }
      
      // Assertions to validate our analysis
      expect(analysis.diagnosticLimitations.length).toBeGreaterThanOrEqual(5)
      expect(analysis.suggestedImprovements.length).toBeGreaterThanOrEqual(5) 
      expect(analysis.expectedDiagnosticValue.length).toBeGreaterThanOrEqual(4)
      
      // The current query should have significant diagnostic limitations
      const hasExpectedLimitations = analysis.diagnosticLimitations.some(limitation => 
        /error|baseline|correlation|trace/.test(limitation.toLowerCase())
      )
      expect(hasExpectedLimitations).toBe(true)
      
      console.log("\n🔍 Checkout Flow Query Diagnostic Analysis:")
      console.log("\n📋 Current Limitations:")
      analysis.diagnosticLimitations.forEach((limitation, i) => {
        console.log(`   ${i + 1}. ${limitation}`)
      })
      
      console.log("\n💡 Suggested Improvements:")
      analysis.suggestedImprovements.forEach((improvement, i) => {
        console.log(`   ${i + 1}. ${improvement}`)
      })
      
      console.log("\n🎯 Expected Diagnostic Value:")
      analysis.expectedDiagnosticValue.forEach((value, i) => {
        console.log(`   ${i + 1}. ${value}`)
      })
    })
    
    it("should propose an improved diagnostic query for checkout flow", () => {
      // Improved query that addresses the diagnostic limitations
      const improvedCheckoutQuery = `
        WITH checkout_metrics AS (
          SELECT 
            toStartOfMinute(start_time) AS minute,
            service_name,
            operation_name,
            count() AS request_count,
            countIf(status_code != 'OK') AS error_count,
            quantile(0.5)(duration_ns / 1e6) AS p50_ms,
            quantile(0.95)(duration_ns / 1e6) AS p95_ms,
            quantile(0.99)(duration_ns / 1e6) AS p99_ms,
            max(duration_ns / 1e6) AS max_ms
          FROM otel.traces
          WHERE 
            service_name IN ('frontend', 'cart', 'checkout', 'payment', 'email')
            AND start_time >= now() - INTERVAL 15 MINUTE  -- Recent data for real-time diagnosis
          GROUP BY minute, service_name, operation_name
        ),
        service_health AS (
          SELECT 
            minute,
            service_name,
            sum(request_count) AS total_requests,
            sum(error_count) AS total_errors,
            round(sum(error_count) * 100.0 / sum(request_count), 2) AS error_rate_pct,
            avg(p95_ms) AS avg_p95_ms,
            max(max_ms) AS worst_latency_ms
          FROM checkout_metrics
          GROUP BY minute, service_name
        ),
        bottleneck_analysis AS (
          SELECT 
            minute,
            service_name,
            operation_name,
            request_count,
            p95_ms,
            -- Identify operations consuming the most total time (bottlenecks)
            request_count * p95_ms AS total_time_impact_ms,
            -- Flag anomalies: > 2 standard deviations from mean
            CASE 
              WHEN p95_ms > avg(p95_ms) OVER (PARTITION BY service_name, operation_name) + 
                           2 * stddevSamp(p95_ms) OVER (PARTITION BY service_name, operation_name)
              THEN 'ANOMALY'
              ELSE 'NORMAL' 
            END AS performance_status
          FROM checkout_metrics
          WHERE request_count > 5  -- Filter low-volume noise
        )
        SELECT 
          sh.minute,
          sh.service_name,
          sh.total_requests,
          sh.error_rate_pct,
          sh.avg_p95_ms,
          sh.worst_latency_ms,
          -- Add bottleneck context
          ba.operation_name AS worst_operation,
          ba.total_time_impact_ms AS bottleneck_impact_ms,
          ba.performance_status,
          -- Service health score (lower is worse)
          CASE 
            WHEN sh.error_rate_pct > 5 THEN 'CRITICAL'
            WHEN sh.error_rate_pct > 1 OR sh.avg_p95_ms > 1000 THEN 'WARNING'  
            ELSE 'HEALTHY'
          END AS service_health_status
        FROM service_health sh
        LEFT JOIN (
          SELECT DISTINCT ON (minute, service_name) 
            minute, service_name, operation_name, total_time_impact_ms, performance_status
          FROM bottleneck_analysis
          ORDER BY minute, service_name, total_time_impact_ms DESC
        ) ba USING (minute, service_name)
        ORDER BY sh.minute DESC, 
                 CASE sh.service_health_status 
                   WHEN 'CRITICAL' THEN 1 
                   WHEN 'WARNING' THEN 2 
                   ELSE 3 
                 END,
                 sh.error_rate_pct DESC,
                 sh.avg_p95_ms DESC
      `
      
      const improvements: QueryAnalysis = {
        originalQuery: improvedCheckoutQuery,
        description: "Enhanced Checkout Flow Diagnostic Query with Error Analysis and Bottleneck Detection",
        diagnosticLimitations: [
          "Still lacks cross-trace correlation for complete flow analysis",
          "No comparison to historical baselines (would need historical data)",
          "Resource correlation requires additional metrics tables"
        ],
        suggestedImprovements: [
          "Add trace flow analysis to show service call patterns",
          "Include comparison to rolling 7-day averages",
          "Correlate with system metrics if available",
          "Add geographic or user segment analysis"
        ],
        improvedQuery: improvedCheckoutQuery,
        expectedDiagnosticValue: [
          "Clear identification of which service has the highest error rate",
          "Bottleneck analysis showing which operations consume most time", 
          "Service health status for quick triage (CRITICAL/WARNING/HEALTHY)",
          "Performance anomaly detection using statistical thresholds",
          "Real-time 15-minute window for immediate diagnosis",
          "Operation-level detail to pinpoint specific issues within services",
          "Total time impact metrics to prioritize optimization efforts"
        ]
      }
      
      // Validate the improved query addresses the original limitations
      expect(improvements.improvedQuery).toContain("error_count")
      expect(improvements.improvedQuery).toContain("error_rate_pct") 
      expect(improvements.improvedQuery).toContain("bottleneck")
      expect(improvements.improvedQuery).toContain("operation_name")
      expect(improvements.improvedQuery).toContain("INTERVAL 15 MINUTE")
      expect(improvements.improvedQuery).toContain("service_health_status")
      
      // Should have more diagnostic value than the original
      expect(improvements.expectedDiagnosticValue.length).toBeGreaterThan(5)
      
      console.log("\n🚀 Improved Checkout Flow Diagnostic Query:")
      console.log("\n📊 Enhanced Diagnostic Value:")
      improvements.expectedDiagnosticValue.forEach((value, i) => {
        console.log(`   ${i + 1}. ${value}`)
      })
      
      console.log("\n⚠️  Remaining Limitations:")
      improvements.diagnosticLimitations.forEach((limitation, i) => {
        console.log(`   ${i + 1}. ${limitation}`)
      })
    })
    
    it("should identify specific query patterns that improve diagnostics", () => {
      const diagnosticPatterns = {
        "Error Analysis": {
          pattern: "countIf(status_code != 'OK') AS error_count",
          purpose: "Identify failure points in the critical path",
          example: "Shows which service in checkout flow has highest error rate"
        },
        "Volume Context": {
          pattern: "count() AS request_count",
          purpose: "Contextualize performance metrics with load",  
          example: "High latency with low volume suggests different root cause than high latency with high volume"
        },
        "Bottleneck Detection": {
          pattern: "request_count * p95_ms AS total_time_impact_ms",
          purpose: "Identify operations consuming most total time",
          example: "Payment validation taking 500ms with 1000 requests has more impact than email taking 2000ms with 10 requests"
        },
        "Anomaly Detection": {  
          pattern: "p95_ms > avg(p95_ms) OVER (...) + 2 * stddevSamp(p95_ms) OVER (...)",
          purpose: "Automatically flag performance regressions",
          example: "Detect when checkout service suddenly takes 2x longer than usual"
        },
        "Health Scoring": {
          pattern: "CASE WHEN error_rate_pct > 5 THEN 'CRITICAL' ... END",
          purpose: "Provide actionable triage categories",
          example: "Immediately identify which services need urgent attention"
        },
        "Real-time Windows": {
          pattern: "start_time >= now() - INTERVAL 15 MINUTE", 
          purpose: "Focus on recent data for immediate diagnosis",
          example: "Show current checkout flow health, not historical averages"
        },
        "Operation Breakdown": {
          pattern: "GROUP BY minute, service_name, operation_name",
          purpose: "Drill down to specific operations within services",
          example: "Identify that 'validate_payment' operation is slow, not entire payment service"
        }
      }
      
      // Validate each pattern has diagnostic value
      Object.entries(diagnosticPatterns).forEach(([_name, pattern]) => {
        expect(pattern.pattern).toBeDefined()
        expect(pattern.purpose).toBeDefined() 
        expect(pattern.example).toBeDefined()
        expect(pattern.purpose.length).toBeGreaterThan(20)
        expect(pattern.example.length).toBeGreaterThan(30)
      })
      
      console.log("\n🔧 Diagnostic Query Patterns:")
      Object.entries(diagnosticPatterns).forEach(([name, pattern]) => {
        console.log(`\n   ${name}:`)
        console.log(`     Pattern: ${pattern.pattern}`)
        console.log(`     Purpose: ${pattern.purpose}`)
        console.log(`     Example: ${pattern.example}`)
      })
      
      expect(Object.keys(diagnosticPatterns)).toHaveLength(7)
    })
  })
  
  describe("Query Generation Prompt Improvements", () => {
    
    it("should propose improved prompts for diagnostic query generation", () => {
      const currentPromptLimitations = [
        "Generic 'analysis goal' doesn't specify diagnostic requirements",
        "No guidance on error analysis inclusion", 
        "No requirement for volume/context metrics",
        "No specification of anomaly detection patterns",
        "No guidance on time window selection for real-time diagnosis",
        "No requirement for operation-level breakdown",
        "No health scoring or triage categorization guidance"
      ]
      
      const improvedPromptElements = [
        "Specify critical path diagnostic requirements explicitly",
        "Require error analysis (error rates, failure patterns)",
        "Mandate volume context (request counts, throughput)", 
        "Include anomaly detection using statistical methods",
        "Use appropriate time windows (15-min for real-time, hourly for trends)",
        "Require operation-level detail within services",
        "Include health scoring for immediate triage",
        "Add bottleneck analysis (total time impact metrics)",
        "Specify comparison to baselines when possible"
      ]
      
      const sampleImprovedPrompt = `
        You are a ClickHouse expert specializing in DIAGNOSTIC queries for critical path analysis.
        
        Critical Path: ${'{path.name}'}
        Services: ${'{path.services.join(", ")}'}
        
        DIAGNOSTIC REQUIREMENTS (ALL MUST BE INCLUDED):
        1. ERROR ANALYSIS: Include error rates and failure patterns for each service
        2. VOLUME CONTEXT: Include request counts to contextualize performance metrics  
        3. BOTTLENECK DETECTION: Calculate total time impact (request_count * latency) to identify bottlenecks
        4. ANOMALY DETECTION: Use statistical methods to flag performance regressions
        5. OPERATION BREAKDOWN: Group by operation_name within services for specific diagnosis
        6. HEALTH SCORING: Categorize services as CRITICAL/WARNING/HEALTHY for triage
        7. REAL-TIME FOCUS: Use 15-minute windows for recent diagnosis, avoid long historical periods
        
        QUERY STRUCTURE REQUIREMENTS:
        - Use CTEs (WITH clauses) for complex analysis
        - Include multiple aggregation levels (operation, service, overall)
        - Order results by severity/impact for immediate action
        - Filter out low-volume noise (request_count > threshold)
        
        The query MUST help diagnose WHY this path is critical and WHAT specific actions to take.
        
        Return ONLY the SQL query without explanation.
      `
      
      expect(currentPromptLimitations.length).toBeGreaterThanOrEqual(5)
      expect(improvedPromptElements.length).toBeGreaterThanOrEqual(8)
      expect(sampleImprovedPrompt).toContain("DIAGNOSTIC REQUIREMENTS")
      expect(sampleImprovedPrompt).toContain("ERROR ANALYSIS")
      expect(sampleImprovedPrompt).toContain("BOTTLENECK DETECTION")
      
      console.log("\n📝 Query Generation Prompt Analysis:")
      console.log("\n❌ Current Prompt Limitations:")
      currentPromptLimitations.forEach((limitation, i) => {
        console.log(`   ${i + 1}. ${limitation}`)
      })
      
      console.log("\n✅ Improved Prompt Elements:")
      improvedPromptElements.forEach((element, i) => {
        console.log(`   ${i + 1}. ${element}`)
      })
      
      console.log("\n📋 Sample Improved Prompt Structure:")
      console.log(sampleImprovedPrompt.substring(0, 500) + "...")
    })
  })
})